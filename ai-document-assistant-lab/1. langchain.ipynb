{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967c53a9-cb65-49a5-99f4-145651f38bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/ubuntu/.local/lib/python3.10/site-packages (1.68.0)\n",
      "Requirement already satisfied: langchain in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-openai in /home/ubuntu/.local/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: numpy>=2.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (2.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: sounddevice>=0.5.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (0.5.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/.local/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain) (5.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sounddevice>=0.5.1->openai) (1.17.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.local/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.5.1->openai) (2.22)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain-core==0.2.17\n",
    "#!pip install langchain-openai==0.1.17\n",
    "#!pip install pydantic==1.10.8\n",
    "#!pip install pydantic_core==2.18.2\n",
    "!pip install -U openai langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020041bc-3149-4195-b28f-4d38c65cbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-search-results in /home/ubuntu/.local/lib/python3.10/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->google-search-results) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->google-search-results) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->google-search-results) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->google-search-results) (2020.6.20)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wikipedia in /home/ubuntu/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ubuntu/.local/lib/python3.10/site-packages (from wikipedia) (4.13.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.6.20)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in /home/ubuntu/.local/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/ubuntu/.local/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2020.6.20)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results\n",
    "!pip install wikipedia\n",
    "!pip install faiss-cpu \n",
    "!pip install sentence_transformers \n",
    "!pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a332d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field # 예전 방식\n",
    "\n",
    "# from pydantic import BaseModel # 새로운 방식\n",
    "\n",
    "from pydantic.v1 import BaseModel # pydantic.v1 호환이 필요한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd2a51b-6740-4a14-8ad9-fb59e3ec001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11354/1139671788.py:11: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
      "/tmp/ipykernel_11354/1139671788.py:15: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  aimsg = chat([sys, msg])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1990년대의 재즈는 다양한 스타일과 아티스트들이 혼합되어 풍부한 음악적 경험을 제공합니다. 다음은 1990년대의 재즈에서 추천할 만한 5곡입니다:\\n\\n1. **\"Tutu\" - Miles Davis (1986)**  \\n   - 비록 1986년에 발표된 곡이지만, 1990년대에도 많은 사랑을 받았습니다. 전자 재즈의 상징적인 곡으로, 퓨전 재즈의 매력을 잘 보여줍니다.\\n\\n2. **\"In a Silent Way\" - Miles Davis (1992)**  \\n   - 기존의 곡을 리믹스한 버전으로, 미니멀하고 몽환적인 사운드가 포인트입니다.\\n\\n3. **\"Moanin\\'\" - Charles Mingus (1992)**  \\n   - 찰스 밍구스의 클래식 곡이 재조명된 버전으로, 강렬한 리듬과 감성적인 멜로디가 특징입니다.\\n\\n4. **\"Dance of the Infidels\" - McCoy Tyner (1991)**  \\n   - 맥코이 타이너의 독창적인 피아노 연주가 돋보이는 곡으로, 하드 밥 스타일의 정수를 느낄 수 있습니다.\\n\\n5. **\"Take Five\" - Dave Brubeck (1996, 리마스터드)**  \\n   - 이 곡은 원래 1959년에 발표되었지만, 90년대에 리마스터되며 새로운 세대에게도 사랑받았습니다. 독특한 5/4 박자가 특징입니다.\\n\\n이 곡들을 들으시면 1990년대의 재즈 매력을 충분히 느낄 수 있을 거예요!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예전에 사용한대로 AI, Human, System message를 배열로 전달\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "sys = SystemMessage(content=\"당신은 음악 추천을 해주는 전문 AI입니다.\")\n",
    "msg = HumanMessage(content='1990년대 재즈 5곡만 추천해줘.')\n",
    "\n",
    "aimsg = chat([sys, msg])\n",
    "aimsg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e5f17c-6a25-4489-919f-b1e477368296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사파 외에도 베트남에는 아름다운 여행지가 많습니다. 몇 가지 추천해드리자면:\\n\\n1. **하롱베이**: 세계자연유산으로, 섬과 바위가 어우러진 경치가 일품입니다. 하루 투어로 크루즈를 즐길 수 있습니다.\\n\\n2. **호이안**: 전통적인 건축물과 아름다운 해변이 있는 도시로, 밤에는 등불로 물든 경치가 매력적입니다. 식도락과 쇼핑도 즐길 수 있습니다.\\n\\n3. **다낭**: 해변과 산이 어우러진 도시로, 바나힐과 골든브릿지 등 인기 명소가 많습니다. 호이안과 가까워 함께 여행하기 좋습니다.\\n\\n4. **푸꾸옥 섬**: 아름다운 해변과 맑은 바다가 있는 섬으로, 휴양을 즐기기에 최적입니다.\\n\\n5. **하노이**: 베트남의 수도로, 역사와 문화를 느낄 수 있는 곳입니다. 맛있는 길거리 음식과 다양한 관광명소가 있습니다.\\n\\n여행 기간과 관심사에 따라 적합한 장소를 선택해 보세요!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예전에 사용한대로 AI, Human, System message를 배열로 전달\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "sys = SystemMessage(content=\"당신은 여행을 추천해주는 전문 AI입니다.\")\n",
    "msg1 = HumanMessage(content='베트남 사파에 1박 2일 여행 가면 충분할까?')\n",
    "msg2 = AIMessage(content='사파는 1박 2일로 가기에는 너무 멉니다. 일정을 조정하거나 다른 여행지를 선택하시면 어떨까요?')\n",
    "msg3 = HumanMessage(content='음 ... 그러면 어디가 좋을까?')\n",
    "\n",
    "aimsg = chat([sys, msg1, msg2, msg3])\n",
    "aimsg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5f966f-2923-4af7-9e96-bab696d6c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI 여행 추천 서비스 만드는 회사 이름 추천해줘. 기억에 남는 한글 이름으로'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate를 사용하여 각 LLM에 맞는 prompt를 지정할 수 있음\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"상품\"],\n",
    "    template=\"{상품} 만드는 회사 이름 추천해줘. 기억에 남는 한글 이름으로\",\n",
    ")\n",
    "\n",
    "prompt.format(상품=\"AI 여행 추천 서비스\") # 변수가 여러 개 일 때, 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ae1232-2911-463a-838f-47eb2cbf5de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11354/2518977364.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=chat, prompt=prompt)\n",
      "/tmp/ipykernel_11354/2518977364.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(상품=\"학원 추천 서비스\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. **학원지기** - 학원에 대한 전문가가 되어주는 느낌을 줍니다.\\n2. **똑똑학원** - 지혜롭고 스마트한 선택을 도와준다는 의미를 담고 있습니다.\\n3. **학원마중** - 학원을 찾아가는 길에 도움을 준다는 느낌입니다.\\n4. **배움터** - 학습과 성장을 상징하는 이름입니다.\\n5. **스마트학원** - 현대적이고 효율적인 학원 추천을 강조합니다.\\n6. **길잡이학원** - 학생들이 올바른 길을 찾도록 돕는 이미지입니다.\\n7. **숨은명소학원** - 잘 알려지지 않은 우수한 학원을 찾아주는 서비스 느낌입니다.\\n8. **꿈길학원** - 학생들의 꿈을 위한 길잡이로서의 역할을 강조합니다.\\n9. **학원스팟** - 다양한 학원을 쉽게 찾아볼 수 있는 공간의 느낌을 줍니다.\\n10. **참학원** - 진정한 학원을 의미하며 신뢰감을 주는 이름입니다.\\n\\n원하는 느낌이나 방향성을 말씀해 주시면 더 많은 제안을 드릴 수 있습니다!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "chain.run(상품=\"학원 추천 서비스\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cede08e-1a08-40de-b79a-edee95d7950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime la programmation.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 Prompt 별 template 지정도 가능\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)  \n",
    "\n",
    "template=\"You are a helpful assisstant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "\n",
    "chatchain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chatchain.run(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e138db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numexpr in /home/ubuntu/.local/lib/python3.10/site-packages (2.10.2)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from numexpr) (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96ce4ed-c8cd-453a-941f-67f937037653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m아마존의 창업자를 찾고 그의 나이와 배우자의 나이를 곱해야 하므로, 먼저 아마존의 창업자에 대한 정보를 찾아야 한다. \n",
      "Action: wikipedia\n",
      "Action Input: \"Amazon founder\" \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Amazon (company)\n",
      "Summary: Amazon.com, Inc., doing business as Amazon ( , AM-ə-zon; UK also , AM-ə-zən), is an American multinational technology company engaged in e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence. Founded in 1994 by Jeff Bezos in Bellevue, Washington, the company originally started as an online marketplace for books but gradually expanded its offerings to include a wide range of product categories, referred to as \"The Everything Store\". Today, Amazon is considered one of the Big Five American technology companies, the other four being Alphabet, Apple, Meta, and Microsoft.\n",
      "The company has multiple subsidiaries, including Amazon Web Services, providing cloud computing; Zoox, a self-driving car division; Kuiper Systems, a satellite Internet provider; and Amazon Lab126, a computer hardware R&D provider. Other subsidiaries include Ring, Twitch, IMDb, and Whole Foods Market. Its acquisition of Whole Foods in August 2017 for US$13.4 billion substantially increased its market share and presence as a physical retailer. Amazon also distributes a variety of downloadable and streaming content through its Amazon Prime Video, MGM+, Amazon Music, Twitch, Audible and Wondery units. It publishes books through its publishing arm, Amazon Publishing, produces and distributes film and television content through Amazon MGM Studios, including the Metro-Goldwyn-Mayer studio it acquired in March 2022, and owns Brilliance Audio and Audible, which produce and distribute audiobooks, respectively. Amazon also produces consumer electronics—most notably, Kindle e-readers, Echo devices, Fire tablets, and Fire TVs.\n",
      "Amazon has a reputation as a disruptor of industries through technological innovation and aggressive reinvestment of profits into capital expenditures. As of 2023, it is the world's largest online retailer and marketplace, smart speaker provider, cloud computing service through AWS, live-streaming service through Twitch, and Internet company as measured by revenue and market share. In 2021, it surpassed Walmart as the world's largest retailer outside of China, driven in large part by its paid subscription plan, Amazon Prime, which has close to 200 million subscribers worldwide. It is the second-largest private employer in the United States and the second-largest company in the world and in the U.S. by revenue as of 2024 (after Walmart). As of October 2024, Amazon is the 12th-most visited website in the world and 84% of its traffic comes from the United States. Amazon is also the global leader in research and development spending, with R&D expenditure of US$73 billion in 2022. Amazon has been criticized on various grounds, including but not limited to customer data collection practices, a toxic work culture, censorship, tax avoidance, and anti-competitive practices. \n",
      "\n",
      "\n",
      "\n",
      "Page: Jeff Bezos\n",
      "Summary: Jeffrey Preston Bezos ( BAY-zohss; né Jorgensen; born January 12, 1964) is an American businessman best known as the founder, executive chairman, and former president and CEO of Amazon, the world's largest e-commerce and cloud computing company. According to Forbes, as of March 12 2025, Bezos' estimated net worth stood at US$209.5 billion, making him the second richest individual in the world. He was the wealthiest person from 2017 to 2021, according to Forbes and the Bloomberg Billionaires Index.\n",
      "Bezos was born in Albuquerque and raised in Houston and Miami. He graduated from Princeton University in 1986 with degrees in electrical engineering and computer science. He worked on Wall Street in a variety of related fields from 1986 to early 1994. Bezos founded Amazon in mid-1994 on a road trip from New York City to Seattle. The company began as an online bookstore and has since expanded to a variety of other e-commerce products and services, including video and audio streaming, cloud computing, and artificial intelligence. It is the world's largest online sales company, the largest Internet c\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found that the founder of Amazon is Jeff Bezos, who was born on January 12, 1964. Now, I need to find out the age of his spouse to calculate the product of their ages. \n",
      "\n",
      "Action: wikipedia  \n",
      "Action Input: \"Jeff Bezos spouse\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Miguel Bezos\n",
      "Summary: Miguel Ángel \"Mike\" Bezos Pérez (born (1945-09-29)September 29, 1945) is a Cuban-American billionaire and philanthropist who provided the initial investment to launch Amazon.com. He is a co-founder of the Bezos Family Foundation.\n",
      "He is the adoptive father of Jeff Bezos, the father of Mark Bezos and the husband of Jackie Bezos.\n",
      "\n",
      "Page: Jackie Bezos\n",
      "Summary: Jacklyn Bezos (née Gise, formerly Jorgensen; born December 29, 1946) is an American billionaire and philanthropist who provided the initial investment to launch Amazon.com. She is a co-founder of the Bezos Family Foundation. \n",
      "She is the mother of Jeff Bezos and Mark Bezos, and the ex-wife of Ted Jorgensen.\n",
      "\n",
      "Page: Jeff Bezos\n",
      "Summary: Jeffrey Preston Bezos ( BAY-zohss; né Jorgensen; born January 12, 1964) is an American businessman best known as the founder, executive chairman, and former president and CEO of Amazon, the world's largest e-commerce and cloud computing company. According to Forbes, as of March 12 2025, Bezos' estimated net worth stood at US$209.5 billion, making him the second richest individual in the world. He was the wealthiest person from 2017 to 2021, according to Forbes and the Bloomberg Billionaires Index.\n",
      "Bezos was born in Albuquerque and raised in Houston and Miami. He graduated from Princeton University in 1986 with degrees in electrical engineering and computer science. He worked on Wall Street in a variety of related fields from 1986 to early 1994. Bezos founded Amazon in mid-1994 on a road trip from New York City to Seattle. The company began as an online bookstore and has since expanded to a variety of other e-commerce products and services, including video and audio streaming, cloud computing, and artificial intelligence. It is the world's largest online sales company, the largest Internet company by revenue, and the largest provider of virtual assistants and cloud infrastructure services through its Amazon Web Services branch.\n",
      "Bezos founded the aerospace manufacturer and sub-orbital spaceflight services company Blue Origin in 2000. Blue Origin's New Shepard vehicle reached space in 2015 and afterwards successfully landed back on Earth; he flew into space on Blue Origin NS-16 in 2021. He purchased the major American newspaper The Washington Post in 2013 for $250 million and manages many other investments through his venture capital firm, Bezos Expeditions. In September 2021, Bezos co-founded Altos Labs with Mail.ru founder Yuri Milner.\n",
      "The first centibillionaire on the Forbes Real Time Billionaires Index and the second ever to have achieved the feat since Bill Gates in 1999, Bezos was named the \"richest man in modern history\" after his net worth increased to $150 billion in July 2018. In August 2020, according to Forbes, he had a net worth exceeding $200 billion. On July 5, 2021, Bezos stepped down as the CEO and president of Amazon and took over the role of executive chairman. Amazon Web Services CEO Andy Jassy succeeded Bezos as the CEO and president of Amazon.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found that Jeff Bezos was born on January 12, 1964. Now, I need to find out the age of his spouse, which is MacKenzie Scott, to calculate the product of their ages. \n",
      "\n",
      "Action: wikipedia  \n",
      "Action Input: \"MacKenzie Scott\"  \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/ubuntu/.local/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: MacKenzie Scott\n",
      "Summary: MacKenzie Scott (née Tuttle, formerly Bezos; born April 7, 1970) is an American novelist, philanthropist, and ex-wife of Amazon founder Jeff Bezos. As of December 2024, she has a net worth of US$42.1 billion, according to Bloomberg Billionaires Index; owning a 4% stake in Amazon. As such, Scott is the third-wealthiest woman in the United States and the 38th-wealthiest individual in the world. Scott was named one of Time's 100 most influential people in 2020 and one of the world's 100 most powerful women by Forbes in 2021 and 2023. \n",
      "In 2006, Scott won an American Book Award for her 2005 debut novel, The Testing of Luther Albright. Her second novel, Traps, was published in 2013. She has been executive director of Bystander Revolution, an anti-bullying organization, since she founded it in 2014. She is committed to giving at least half of her wealth to charity as a signatory to the Giving Pledge. Scott made $5.8 billion in charitable gifts in 2020, one of the largest annual distributions by a private individual to working charities. She donated a further $2.7 billion in 2021. As of mid-December 2022, Scott had given a total of $14 billion to over 1600 charitable organizations.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found that Jeff Bezos was born on January 12, 1964, and his ex-wife is MacKenzie Scott, who was born on April 7, 1970. Now, I will calculate their ages and then multiply them.\n",
      "\n",
      "1. Jeff Bezos's age: \n",
      "   - Current year: 2023\n",
      "   - Birth year: 1964\n",
      "   - Age = 2023 - 1964 = 59 years\n",
      "\n",
      "2. MacKenzie Scott's age:\n",
      "   - Current year: 2023\n",
      "   - Birth year: 1970\n",
      "   - Age = 2023 - 1970 = 53 years\n",
      "\n",
      "Now, I will multiply their ages:\n",
      "- Product of their ages = 59 * 53\n",
      "\n",
      "Action: Calculator\n",
      "Action Input: 59 * 53\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3127\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: 3127\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3127'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatOpenAI를 LLM으로 사용하는 agent\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0) \n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=chat)\n",
    "\n",
    "agent = initialize_agent(tools, llm=chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) \n",
    "\n",
    "agent.run(\"아마존의 창업자는 누구인가? 그의 나이와 배우자의 나이를 곱하면 얼마인가?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84a01db-ce84-4ddf-be0d-9976ba3580ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/ubuntu/.local/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7faf95135d80>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7faf940f2740>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_proxy=''), output_parser=StrOutputParser(), llm_kwargs={}))>, coroutine=<bound method Chain.arun of LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7faf95135d80>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7faf940f2740>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_proxy=''), output_parser=StrOutputParser(), llm_kwargs={}))>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47498a86-a6b0-4e43-bbe3-e84d6e338b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Useful for when you need to answer questions about math.\n"
     ]
    }
   ],
   "source": [
    "print(agent.tools[0].description)\n",
    "print(agent.tools[1].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4c1c5cf-26f1-448f-8687-784ca932ed8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11354/2149845611.py:4: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=chat, verbose=True)\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pydantic/main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 인공지능에서 LLM이 뭐야?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LLM은 \"대규모 언어 모델\" (Large Language Model)의 약자입니다. 이러한 모델은 대량의 텍스트 데이터를 사용하여 훈련되어, 자연어를 이해하고 생성하는 능력을 갖추고 있습니다. LLM은 주로 딥러닝의 한 형태인 변환기(Transformer) 아키텍처를 기반으로 하며, 문장 생성, 질문 응답, 번역 등 다양한 자연어 처리 작업에 활용됩니다.\\n\\n예를 들어, GPT-3와 같은 모델은 1750억 개의 매개변수를 가지고 있어 매우 복잡한 언어 패턴을 학습할 수 있습니다. 이 덕분에 LLM은 사람처럼 자연스러운 대화를 나누거나 특정 주제에 대해 정보를 제공하는 데 매우 효과적입니다. LLM의 발전 덕분에 우리는 챗봇, 자동번역기, 콘텐츠 생성 도구 등 다양한 AI 응용 프로그램을 사용하고 있습니다. 궁금한 점이 더 있으면 언제든지 물어보세요!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.9)\n",
    "conversation = ConversationChain(llm=chat, verbose=True)\n",
    "conversation.predict(input=\"인공지능에서 LLM이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd1f46e-daa1-4098-8d3e-4c36f4ec0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 인공지능에서 LLM이 뭐야?\n",
      "AI: LLM은 \"대규모 언어 모델\" (Large Language Model)의 약자입니다. 이러한 모델은 대량의 텍스트 데이터를 사용하여 훈련되어, 자연어를 이해하고 생성하는 능력을 갖추고 있습니다. LLM은 주로 딥러닝의 한 형태인 변환기(Transformer) 아키텍처를 기반으로 하며, 문장 생성, 질문 응답, 번역 등 다양한 자연어 처리 작업에 활용됩니다.\n",
      "\n",
      "예를 들어, GPT-3와 같은 모델은 1750억 개의 매개변수를 가지고 있어 매우 복잡한 언어 패턴을 학습할 수 있습니다. 이 덕분에 LLM은 사람처럼 자연스러운 대화를 나누거나 특정 주제에 대해 정보를 제공하는 데 매우 효과적입니다. LLM의 발전 덕분에 우리는 챗봇, 자동번역기, 콘텐츠 생성 도구 등 다양한 AI 응용 프로그램을 사용하고 있습니다. 궁금한 점이 더 있으면 언제든지 물어보세요!\n",
      "Human: PLM과의 차이를 설명해줘.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PLM은 \"사전 훈련된 언어 모델\" (Pre-trained Language Model)의 약자입니다. LLM과 PLM은 모두 자연어 처리에서 사용되는 모델이지만, 그 정의와 사용 방식에서 약간의 차이가 있습니다.\\n\\nPLM은 일반적으로 대규모 텍스트 데이터에서 사전 훈련(pre-training)되어, 특정한 작업에 맞게 추가적으로 미세 조정(fine-tuning)됩니다. 이와 같은 방식은 PLM이 다양한 언어 처리 작업에서 효과적으로 사용될 수 있게 합니다. 예를 들어, BERT(Bidirectional Encoder Representations from Transformers)와 같은 모델은 PLM의 좋은 예로, 문맥을 이해하고 다양한 NLP 작업에서 뛰어난 성능을 보입니다.\\n\\n반면, LLM은 규모가 더욱 크고, 주로 생성적인 작업에 초점을 맞춘 모델을 지칭합니다. LLM은 더 많은 매개변수와 더 많은 데이터로 훈련되어, 보다 자연스럽고 복잡한 언어 생성이 가능합니다. 즉, 모든 LLM이 PLM일 수 있지만, 모든 PLM이 LLM은 아닙니다.\\n\\n정리하자면, PLM은 사전 훈련된 언어 모델로서 다양한 작업에 사용될 수 있는 반면, LLM은 대규모 언어 모델로서 주로 자연어 생성에 강점을 가진 모델입니다. 궁금한 점이 있다면 더 질문해 주세요!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"PLM과의 차이를 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b7e4767-87f5-4731-be17-7d74b9a309f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='인공지능에서 LLM이 뭐야?', additional_kwargs={}, response_metadata={}), AIMessage(content='LLM은 \"대규모 언어 모델\" (Large Language Model)의 약자입니다. 이러한 모델은 대량의 텍스트 데이터를 사용하여 훈련되어, 자연어를 이해하고 생성하는 능력을 갖추고 있습니다. LLM은 주로 딥러닝의 한 형태인 변환기(Transformer) 아키텍처를 기반으로 하며, 문장 생성, 질문 응답, 번역 등 다양한 자연어 처리 작업에 활용됩니다.\\n\\n예를 들어, GPT-3와 같은 모델은 1750억 개의 매개변수를 가지고 있어 매우 복잡한 언어 패턴을 학습할 수 있습니다. 이 덕분에 LLM은 사람처럼 자연스러운 대화를 나누거나 특정 주제에 대해 정보를 제공하는 데 매우 효과적입니다. LLM의 발전 덕분에 우리는 챗봇, 자동번역기, 콘텐츠 생성 도구 등 다양한 AI 응용 프로그램을 사용하고 있습니다. 궁금한 점이 더 있으면 언제든지 물어보세요!', additional_kwargs={}, response_metadata={}), HumanMessage(content='PLM과의 차이를 설명해줘.', additional_kwargs={}, response_metadata={}), AIMessage(content='PLM은 \"사전 훈련된 언어 모델\" (Pre-trained Language Model)의 약자입니다. LLM과 PLM은 모두 자연어 처리에서 사용되는 모델이지만, 그 정의와 사용 방식에서 약간의 차이가 있습니다.\\n\\nPLM은 일반적으로 대규모 텍스트 데이터에서 사전 훈련(pre-training)되어, 특정한 작업에 맞게 추가적으로 미세 조정(fine-tuning)됩니다. 이와 같은 방식은 PLM이 다양한 언어 처리 작업에서 효과적으로 사용될 수 있게 합니다. 예를 들어, BERT(Bidirectional Encoder Representations from Transformers)와 같은 모델은 PLM의 좋은 예로, 문맥을 이해하고 다양한 NLP 작업에서 뛰어난 성능을 보입니다.\\n\\n반면, LLM은 규모가 더욱 크고, 주로 생성적인 작업에 초점을 맞춘 모델을 지칭합니다. LLM은 더 많은 매개변수와 더 많은 데이터로 훈련되어, 보다 자연스럽고 복잡한 언어 생성이 가능합니다. 즉, 모든 LLM이 PLM일 수 있지만, 모든 PLM이 LLM은 아닙니다.\\n\\n정리하자면, PLM은 사전 훈련된 언어 모델로서 다양한 작업에 사용될 수 있는 반면, LLM은 대규모 언어 모델로서 주로 자연어 생성에 강점을 가진 모델입니다. 궁금한 점이 있다면 더 질문해 주세요!', additional_kwargs={}, response_metadata={})]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d6347c-2c99-4d28-b9e6-b7585d72a043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Created a chunk of size 2293, which is longer than the specified 1000\n",
      "Created a chunk of size 2843, which is longer than the specified 1000\n",
      "Created a chunk of size 6664, which is longer than the specified 1000\n",
      "Created a chunk of size 2194, which is longer than the specified 1000\n",
      "Created a chunk of size 1471, which is longer than the specified 1000\n",
      "Created a chunk of size 2774, which is longer than the specified 1000\n",
      "Created a chunk of size 1873, which is longer than the specified 1000\n",
      "Created a chunk of size 3432, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 2746, which is longer than the specified 1000\n",
      "Created a chunk of size 3230, which is longer than the specified 1000\n",
      "Created a chunk of size 1099, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "# https://api.python.langchain.com/en/latest/api_reference.html#module-langchain.document_loaders\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(web_path=\"https://ko.wikipedia.org/wiki/IU\")\n",
    "documents = loader.load()\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "692cd1a0-48c1-48b6-977c-a2a48ea96fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://ko.wikipedia.org/wiki/IU', 'title': '아이유 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='아이유 - 위키백과, 우리 모두의 백과사전\\n\\n\\n본문으로 이동\\n\\n주 메뉴\\n\\n주 메뉴\\n사이드바로 이동\\n숨기기\\n\\n\\t\\t둘러보기\\n\\t\\n\\n\\n대문최근 바뀜요즘 화제임의의 문서로특수 문서 목록\\n\\n\\t\\t사용자 모임\\n\\t\\n\\n\\n사랑방사용자 모임관리 요청\\n\\n\\t\\t편집 안내\\n\\t\\n\\n\\n소개도움말정책과 지침질문방\\n\\n검색\\n\\n검색\\n\\n\\n보이기\\n\\n\\n기부\\n\\n계정 만들기\\n\\n로그인\\n\\n\\n개인 도구\\n\\n기부 계정 만들기 로그인\\n\\n\\t\\t로그아웃한 편집자를 위한 문서 더 알아보기\\n\\n기여토론\\n\\n\\n목차\\n사이드바로 이동\\n숨기기\\n\\n\\n처음 위치\\n\\n1\\n학력\\n\\n\\n2\\n활동\\n\\n\\n활동 하위섹션 토글하기\\n\\n2.1\\n2008-2010\\n\\n\\n2.2\\n2011-2013\\n\\n\\n2.3\\n2014-2016\\n\\n\\n2.4\\n2017-2018\\n\\n\\n2.5\\n2019-2020\\n\\n\\n2.6\\n2021-2022\\n\\n\\n2.7\\n2023-2024\\n\\n\\n3\\n음반 목록\\n\\n\\n4\\n음반 외 활동 목록\\n\\n\\n5\\n수상 및 후보 목록\\n\\n\\n6\\n사건\\n\\n\\n7\\n같이 보기\\n\\n\\n8\\n각주\\n\\n\\n각주 하위섹션 토글하기\\n\\n8.1\\n내용주\\n\\n\\n8.2\\n참조주\\n\\n\\n9\\n외부 링크\\n\\n\\n목차 토글\\n\\n아이유\\n\\n61개 언어'),\n",
       " Document(metadata={'source': 'https://ko.wikipedia.org/wiki/IU', 'title': '아이유 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='العربيةمصرىتۆرکجهBasa BaliBikol CentralБългарскиCatalàCebuanoکوردیČeštinaDanskDeutschKadazandusunΕλληνικάEnglishEsperantoEspañolEestiEuskaraفارسیSuomiFrançaisहिन्दीKreyòl ayisyenMagyarՀայերենInterlinguaBahasa IndonesiaItaliano日本語JawaҚазақшаLatinaMāoriമലയാളംМонголBahasa Melayuမြန်မာဘာသာNederlandsNorsk bokmålPolskiPortuguêsRomânăРусскийSimple EnglishSoomaaligaСрпски / srpskiSesothoSundaSvenskaதமிழ்ไทยTagalogSetswanaTürkçeУкраїнськаOʻzbekcha / ўзбекчаTiếng Việt中文閩南語 / Bân-lâm-gú粵語\\n\\n링크 편집\\n\\n문서토론\\n\\n한국어\\n\\n읽기원본 보기역사 보기\\n\\n도구\\n\\n도구\\n사이드바로 이동\\n숨기기\\n\\n\\t\\t동작\\n\\t\\n\\n\\n읽기원본 보기역사 보기\\n\\n\\t\\t일반\\n\\t\\n\\n\\n여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR 코드 다운로드\\n\\n\\t\\t인쇄/내보내기\\n\\t\\n\\n\\n책 만들기PDF로 다운로드인쇄용 판\\n\\n\\t\\t다른 프로젝트\\n\\t\\n\\n\\n위키미디어 공용위키데이터 항목\\n\\n보이기\\n사이드바로 이동\\n숨기기\\n\\n위키백과, 우리 모두의 백과사전.\\n\\n(IU에서 넘어옴)'),\n",
       " Document(metadata={'source': 'https://ko.wikipedia.org/wiki/IU', 'title': '아이유 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}, page_content='다른 뜻에 대해서는 아이유 (동음이의) 문서를 참고하십시오. IU는 여기로 연결됩니다. 다른 뜻에 대해서는 IU (동음이의) 문서를 참고하십시오.\\n아이유2022년 11월 25일 청룡영화상에서의 아이유기본 정보본명이지은출생1993년 5월 16일(1993-05-16)(31세)대한민국 서울특별시 성동구 송정동성별여성직업가수, 배우장르댄스, 발라드, 어쿠스틱, R&B활동 시기2008년~학력동덕여자고등학교 (졸업)레이블카카오엔터테인먼트, EMI 뮤직 재팬소속사EDAM 엔터테인먼트서명웹사이트edam-ent.com유튜브채널이지금 [IU Official]분야일상, 음악개설일2017년 2월 13일구독자 수978만\\xa0명(2024년 10월 6일 기준)총 조회수3,150,968,674회(2024년 10월 6일 기준)vte\\n\\n아이유(IU, 본명:\\xa0이지은, 李知恩[1], 1993년 5월 16일~)는 대한민국의 싱어송라이터, 작곡가, 배우이다. 2007년 로엔 엔터테인먼트(현 카카오 엔터테인먼트) 연습생으로 전속 계약을 맺고 15세의 나이에 2008년 첫 EP인 로스트 앤 파운드(Lost and Found)를 통해 가수로 데뷔했다.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36be6f88-571b-4010-bbdb-af25b75a43bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11354/4030962451.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "#embeddings = HuggingFaceEmbeddings() # sentence-transformers/all-mpnet-base-v2\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=embeddings,\n",
    "    ).from_loaders([loader])\n",
    "\n",
    "# 파일로 저장\n",
    "index.vectorstore.save_local(\"faiss-nj-IU\")\n",
    "# db = FAISS.load_local(\"faiss-nj-IU\", embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c656357-f0e7-439b-b6c6-14927f4e7c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아이유의 데뷔곡은 \"미아\"입니다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유의 데뷔곡은?\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aebc9b7c-64b9-4cd5-be7d-f2e525e6a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아이유의 나이는 31세입니다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유의 나이는?\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1917167b-5b64-4e99-9b8e-17a6047d5787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아이유는 1993년 5월 16일에 태어났으므로, 2025년 3월 21일 현재로서 31세입니다.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유의 나이는? (오늘은 2025년 3월 21일)\", llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "403356b0-5ef9-45a1-b0d7-743866575946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 아이유가 지금까지 총 몇 회의 콘서트를 했는지에 대한 정보는 알 수 없습니다.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.query(\"아이유는 지금까지 총 콘서트를 몇회했는가?\", llm=chat, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
