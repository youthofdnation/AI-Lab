{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain-core==0.2.17\n",
    "#!pip install langchain-openai==0.1.17\n",
    "#!pip install pydantic==1.10.8\n",
    "#!pip install pydantic_core==2.18.2\n",
    "!pip install -U openai langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field # 예전 방식\n",
    "\n",
    "# from pydantic import BaseModel # 새로운 방식\n",
    "\n",
    "from pydantic.v1 import BaseModel # pydantic.v1 호환이 필요한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36680/3759826758.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model=\"gpt-4o-mini\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'왜 아이스크림은 항상 행복할까요?\\n\\n왜냐하면 항상 \"스쿱\"을 받으니까요! 🍦😄'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}에 대한 간단한 농담을 말해줘.\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser # LCEL의 기본 파이프라인\n",
    "\n",
    "chain.invoke({\"topic\": \"아이스크림\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: docarray in /home/ubuntu/.local/lib/python3.10/site-packages (0.40.0)\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (2.2.4)\n",
      "Requirement already satisfied: orjson>=3.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (3.10.15)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (2.10.6)\n",
      "Requirement already satisfied: rich>=13.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (13.9.4)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (2.32.0.20250306)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install docarray tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36680/755495277.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding=OpenAIEmbeddings(),\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain docarray tiktoken\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"해리슨은 학교에서 일합니다.\", \"곰은 꿀을 좋아해\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"다음 지문에만 근거해서 질문에 답하세요:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel( # 여러개의 Runnable을 병렬적으로 실행\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} # RunnablePassthrough는 값을 입력받아 그대로 전달하는 객체\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# retrieval | prompt | model | output. RAG의 기본 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'답변: 해리슨은 학교에서 일합니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"해리슨은 어디에서 일하나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'답변: 곰은 꿀을 좋아합니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke(\"곰은 무엇을 좋아하나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "왜 아이스크림은 항상 행복할까요?\n",
      "\n",
      "왜냐하면 항상 \"스쿱\"을 즐기니까요! 🍦😄"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 간단한 농담을 해줘.\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "for chunk in chain.stream(\"ice cream\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['왜 아이스크림은 항상 기분이 좋을까요? \\n\\n왜냐하면 항상 \"스쿱\"이 좋거든요! 🍦😄',\n",
       " '스파게티가 파스타 모임에서 왜 항상 웃고 있을까요? \\n\\n왜냐하면 항상 \"면\"세가 좋으니까요! 🍝😄',\n",
       " '왜 만두가 항상 행복할까요? \\n\\n늘 속이 꽉 차 있으니까요! 😄']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([\"아이스크림\", \"스파게티\", \"만두\"])\n",
    "\n",
    "# stream: 입력에 대해 청크를 스트리밍\n",
    "# invoke: 입력에 대해 체인을 호출\n",
    "# batch: 입력목록에 대해 체인을 배치로 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'왜 아이스크림은 항상 행복할까요? \\n\\n왜냐하면 항상 \"스쿱\"을 가지고 있으니까요! 🍦😄'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke(\"ice cream\")\n",
    "\n",
    "# astream: 비동기로 입력에 대해 청크를 스트리밍\n",
    "# ainvoke: 비동기로 입력에 대해 체인을 호출\n",
    "# abatch: 비동기로 입력목록에 대해 체인을 배치로 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아이스크림이 왜 학교에 가고 싶어 했을까요? \\n\\n왜냐하면 더 많은 \"스쿨\"을 갖고 싶었거든요! 🍦😄',\n",
       " '왜 스파게티는 항상 좋은 기분을 유지할까요? \\n\\n왜냐하면 항상 \"파스타\"한 기분이니까요! 🍝😄',\n",
       " '왜 만두는 항상 행복할까요? \\n\\n왜냐하면 속이 꽉 차있어서 항상 기분이 좋거든요! 😄']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch(\n",
    "    [\"아이스크림\", \"스파게티\", \"만두\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'root': {'title': 'Root'}},\n",
       " 'required': ['root'],\n",
       " 'title': 'RunnableParallel<topic>Input',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'StrOutputParserOutput', 'type': 'string'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.model_json_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
