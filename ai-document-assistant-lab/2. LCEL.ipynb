{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain-core==0.2.17\n",
    "#!pip install langchain-openai==0.1.17\n",
    "#!pip install pydantic==1.10.8\n",
    "#!pip install pydantic_core==2.18.2\n",
    "!pip install -U openai langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel, Field # ì˜ˆì „ ë°©ì‹\n",
    "\n",
    "# from pydantic import BaseModel # ìƒˆë¡œìš´ ë°©ì‹\n",
    "\n",
    "from pydantic.v1 import BaseModel # pydantic.v1 í˜¸í™˜ì´ í•„ìš”í•œ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36680/3759826758.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  model = ChatOpenAI(model=\"gpt-4o-mini\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ í–‰ë³µí• ê¹Œìš”?\\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì„ ë°›ìœ¼ë‹ˆê¹Œìš”! ğŸ¦ğŸ˜„'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic}ì— ëŒ€í•œ ê°„ë‹¨í•œ ë†ë‹´ì„ ë§í•´ì¤˜.\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser # LCELì˜ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "chain.invoke({\"topic\": \"ì•„ì´ìŠ¤í¬ë¦¼\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: docarray in /home/ubuntu/.local/lib/python3.10/site-packages (0.40.0)\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (2.2.4)\n",
      "Requirement already satisfied: orjson>=3.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (3.10.15)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (2.10.6)\n",
      "Requirement already satisfied: rich>=13.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (13.9.4)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (2.32.0.20250306)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=13.1.0->docarray) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install docarray tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36680/755495277.py:12: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding=OpenAIEmbeddings(),\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain docarray tiktoken\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"í•´ë¦¬ìŠ¨ì€ í•™êµì—ì„œ ì¼í•©ë‹ˆë‹¤.\", \"ê³°ì€ ê¿€ì„ ì¢‹ì•„í•´\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"ë‹¤ìŒ ì§€ë¬¸ì—ë§Œ ê·¼ê±°í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel( # ì—¬ëŸ¬ê°œì˜ Runnableì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} # RunnablePassthroughëŠ” ê°’ì„ ì…ë ¥ë°›ì•„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” ê°ì²´\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# retrieval | prompt | model | output. RAGì˜ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹µë³€: í•´ë¦¬ìŠ¨ì€ í•™êµì—ì„œ ì¼í•©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"í•´ë¦¬ìŠ¨ì€ ì–´ë””ì—ì„œ ì¼í•˜ë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹µë³€: ê³°ì€ ê¿€ì„ ì¢‹ì•„í•©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke(\"ê³°ì€ ë¬´ì—‡ì„ ì¢‹ì•„í•˜ë‚˜ìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ í–‰ë³µí• ê¹Œìš”?\n",
      "\n",
      "ì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì„ ì¦ê¸°ë‹ˆê¹Œìš”! ğŸ¦ğŸ˜„"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}ì— ëŒ€í•œ ê°„ë‹¨í•œ ë†ë‹´ì„ í•´ì¤˜.\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "for chunk in chain.stream(\"ice cream\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ ê¸°ë¶„ì´ ì¢‹ì„ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì´ ì¢‹ê±°ë“ ìš”! ğŸ¦ğŸ˜„',\n",
       " 'ìŠ¤íŒŒê²Œí‹°ê°€ íŒŒìŠ¤íƒ€ ëª¨ì„ì—ì„œ ì™œ í•­ìƒ ì›ƒê³  ìˆì„ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ë©´\"ì„¸ê°€ ì¢‹ìœ¼ë‹ˆê¹Œìš”! ğŸğŸ˜„',\n",
       " 'ì™œ ë§Œë‘ê°€ í•­ìƒ í–‰ë³µí• ê¹Œìš”? \\n\\nëŠ˜ ì†ì´ ê½‰ ì°¨ ìˆìœ¼ë‹ˆê¹Œìš”! ğŸ˜„']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([\"ì•„ì´ìŠ¤í¬ë¦¼\", \"ìŠ¤íŒŒê²Œí‹°\", \"ë§Œë‘\"])\n",
    "\n",
    "# stream: ì…ë ¥ì— ëŒ€í•´ ì²­í¬ë¥¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "# invoke: ì…ë ¥ì— ëŒ€í•´ ì²´ì¸ì„ í˜¸ì¶œ\n",
    "# batch: ì…ë ¥ëª©ë¡ì— ëŒ€í•´ ì²´ì¸ì„ ë°°ì¹˜ë¡œ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì™œ ì•„ì´ìŠ¤í¬ë¦¼ì€ í•­ìƒ í–‰ë³µí• ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"ìŠ¤ì¿±\"ì„ ê°€ì§€ê³  ìˆìœ¼ë‹ˆê¹Œìš”! ğŸ¦ğŸ˜„'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke(\"ice cream\")\n",
    "\n",
    "# astream: ë¹„ë™ê¸°ë¡œ ì…ë ¥ì— ëŒ€í•´ ì²­í¬ë¥¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "# ainvoke: ë¹„ë™ê¸°ë¡œ ì…ë ¥ì— ëŒ€í•´ ì²´ì¸ì„ í˜¸ì¶œ\n",
    "# abatch: ë¹„ë™ê¸°ë¡œ ì…ë ¥ëª©ë¡ì— ëŒ€í•´ ì²´ì¸ì„ ë°°ì¹˜ë¡œ í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì•„ì´ìŠ¤í¬ë¦¼ì´ ì™œ í•™êµì— ê°€ê³  ì‹¶ì–´ í–ˆì„ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ ë” ë§ì€ \"ìŠ¤ì¿¨\"ì„ ê°–ê³  ì‹¶ì—ˆê±°ë“ ìš”! ğŸ¦ğŸ˜„',\n",
       " 'ì™œ ìŠ¤íŒŒê²Œí‹°ëŠ” í•­ìƒ ì¢‹ì€ ê¸°ë¶„ì„ ìœ ì§€í• ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ í•­ìƒ \"íŒŒìŠ¤íƒ€\"í•œ ê¸°ë¶„ì´ë‹ˆê¹Œìš”! ğŸğŸ˜„',\n",
       " 'ì™œ ë§Œë‘ëŠ” í•­ìƒ í–‰ë³µí• ê¹Œìš”? \\n\\nì™œëƒí•˜ë©´ ì†ì´ ê½‰ ì°¨ìˆì–´ì„œ í•­ìƒ ê¸°ë¶„ì´ ì¢‹ê±°ë“ ìš”! ğŸ˜„']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.abatch(\n",
    "    [\"ì•„ì´ìŠ¤í¬ë¦¼\", \"ìŠ¤íŒŒê²Œí‹°\", \"ë§Œë‘\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'root': {'title': 'Root'}},\n",
       " 'required': ['root'],\n",
       " 'title': 'RunnableParallel<topic>Input',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'StrOutputParserOutput', 'type': 'string'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.output_schema.model_json_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
